\documentclass[12pt]{article}

\setlength{\parskip}{1em}

\usepackage[T1]{fontenc}
\usepackage[a4paper, margin=0.7in]{geometry}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{subcaption}


\usepackage{hyperref}
\hypersetup{
  colorlinks=true,
  linkcolor=blue,
  urlcolor=blue,
  pdftitle={PC40 Hands-on: UPC}
}

% \definecolor{gray}{rgb}{0.5,0.5,0.5}
% \definecolor{purple}{rgb}{0.58,0,0.82}
\definecolor{bgColor}{rgb}{0.95,0.95,0.92}
\lstdefinestyle{C}{
    backgroundcolor=\color{bgColor},
    commentstyle=\color{gray},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{gray},
    stringstyle=\color{purple},
    basicstyle=\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2,
    language=C
}

\newcommand{\us}[0]{${\mu}s$}

\title{PC40 Hands-on: UPC}
\author{Adrien Burgun}
\date{Automne 2021}
% \graphicspath{{report/}}

\begin{document}
\maketitle

\begin{abstract}
  For this hands-on assignement, I wanted to measure the performance of the different versions of the code and compare them to measure speedups.
  For this reason, my code diverges slightly from the template that was given to us, as I needed to insert a timing method and avoid refactoring the code.

  You will find in this report listings of the different versions of the code, alongside experimental measurements and commentaries.

  The source code itself, this report's source code and instructions on how to build and run the code yourself can be found on this project's git repository: \url{https://github.com/adri326/pc40-upc/}.
\end{abstract}

\section{Simplified 1D Laplace solver}

\subsection{C implementation}

The C implementation of the laplace solver has been slightly modified to time the main loop.
It is single-threaded but the implementation allows for compiler SIMD optimizations.
Settings common to every version (vector size, epsilon, max number of iterations) have been placed in a file called \texttt{settings.h}.

This code has been compiled with \texttt{gcc v4.9.0} and run on the \texttt{mesoshared} server, yielding the following results:

\begin{table}[h]
  \centering\begin{tabular}{|c|c|c|}
    \hline
    Options & Time (avg) & CI ($\sigma=0.01$) \\
    \hline
    \texttt{-O0} & 450\us/iter & $\pm$ 10\us/iter \\
    \texttt{-O3} & 140\us/iter & $\pm$ 10\us/iter \\
    \hline
  \end{tabular}
  \caption{Timing results for the C implementation of the 1D Laplace solver (Listing~\ref{lst:laplace2})}
  \label{tab:laplace2}
\end{table}

\lstinputlisting[style=C, label={lst:laplace2}, caption={
  C implementation of the 1D Laplace solver
}]{laplace/ex2.c}

\subsection{Porting the C code to UPC}

The base C implementation was designed to be able to quickly port it to UPC.
A new \texttt{if} statement had to be inserted in the \texttt{for} loop within \texttt{iteration()}.
Additionally, several lines had to only be executed by the thread 0, so additional conditionals were added when needed.
Finally, the \texttt{x}, \texttt{xnew} and \texttt{b} arrays were made shared and \texttt{upc\_barrier} statements were added at the end of \texttt{init}, \texttt{iteration} and \texttt{copy\_array}.

This code was compiled with \texttt{upcc v2.22.0 + gcc v4.2.4} and run on the \texttt{mesoshared} server, yielding the following results:

\begin{table}[h]
  \centering\begin{tabular}{|c|c|c|}
    \hline
    Threads & Time (avg) & CI ($\sigma=0.01$) \\
    \hline
    2 & 515.2\us/iter & $\pm$ 3.9\us/iter \\
    3 & 536.2\us/iter & $\pm$ 2.4\us/iter \\
    4 & 312.4\us/iter & $\pm$ 2.0\us/iter \\
    8 & 204.0\us/iter & $\pm$ 2.0\us/iter \\
    16 & 166.2\us/iter & $\pm$ 2.5\us/iter \\
    32 & 150.4\us/iter & $\pm$ 3.2\us/iter \\
    \hline
  \end{tabular}
  \caption{Timing results for the first UPC implementation of the 1D Laplace solver (Listing~\ref{lst:laplace3})}
  \label{tab:laplace3}
\end{table}

When compiled and run with 3 threads, the code runs noticeably slower. For curiosity, I ran the code with 24 and 31 threads and obtained a similar slowdown:

\begin{center}
  Threads = 24, \quad Time = 252.6\us/iter $\pm$ 3.7\us/iter \enspace (expected $\approx 160$ \us/iter) \\
  Threads = 31, \quad Time = 317.6\us/iter $\pm$ 4.4\us/iter \enspace (expected $\approx 150$ \us/iter)
\end{center}

\lstinputlisting[style=C, label={lst:laplace3}, caption={
  First UPC implementation of the 1D Laplace solver
}]{laplace/ex3.upc}

\subsection{Optimizing the inner for loop}

The first step in optimizing our UPC implementation of the 1D Laplace equation solver is to replace the \texttt{for (...) if (...)} with a single, more efficient \texttt{for} loop.

To achieve this, only the \texttt{iteration()} function had to be changed.
This transformation is shown in Figure~\ref{fig:laplace34}

This change greatly increases the speed of the program:

\begin{table}[ht]
  \centering\begin{tabular}{|c|c|c|}
    \hline
    Threads & Time (avg) & CI ($\sigma=0.01$) \\
    \hline
    2 & 482.0\us/iter & $\pm$ 3.2\us/iter \\
    4 & 265.2\us/iter & $\pm$ 2.3\us/iter \\
    8 & 128.8\us/iter & $\pm$ 1.6\us/iter \\
    16 & 74.6\us/iter & $\pm$ 3.1\us/iter \\
    32 & 46.0\us/iter & $\pm$ 2.5\us/iter \\
    \hline
  \end{tabular}
  \caption{Timing results for the second UPC implementation of the 1D Laplace solver}
  \label{tab:laplace4}
\end{table}

\begin{figure}[ht]
  \begin{subfigure}[b]{0.49\columnwidth}
    \begin{lstlisting}[style=C, numbers=none]
// ex3.upc:
void iteration() {
  for (size_t i = 1; i < LEN - 1; i++) {
      if (i % THREADS == MYTHREAD) {
          x_new[i] = 0.5 * (x[i-1] + x[i+1] + b[i]);
      }
  }

  if (MYTHREAD == 0) x_new[0] = x[0];
  if (MYTHREAD == (LEN - 1) % THREADS) x_new[LEN - 1] = x[LEN - 1];

  upc_barrier;
}
    \end{lstlisting}
    \caption{Previous \texttt{iteration()} function from Listing~\ref{lst:laplace3}}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.49\columnwidth}
    \begin{lstlisting}[style=C, numbers=none]
// ex4.upc:
void iteration() {
    size_t i = MYTHREAD;
    if (MYTHREAD == 0) {
        i += THREADS;
        x_new[0] = x[0];
    }

    for (; i < LEN - 1; i += THREADS) {
        x_new[i] = 0.5 * (x[i-1] + x[i+1] + b[i]);
    }

    if (MYTHREAD == THREADS - 1) x_new[LEN - 1] = x[LEN - 1];

    upc_barrier;
}
    \end{lstlisting}
    \caption{New \texttt{iteration()} function without the inner \texttt{if}}
  \end{subfigure}
  \caption{Modification in \texttt{iteration()} to remove the reduce the number of loop iterations.}
  \label{fig:laplace34}
\end{figure}

% \lstinputlisting[style=C, label={lst:laplace4}, caption={
%   Second UPC implementation of the 1D Laplace solver
% }]{laplace/ex4.upc}

\subsection{Optimizing the array blocking factor}

Our next optimization is to increase the blocking factor $B$ for the $x$, $x_{new}$ and $b$ arrays.
Each operation on the item of index $j$ accesses $b[j]$, $x[j-1]$, $x[j+1]$ and $x_{new}[j]$.

With the default block factor of $1$, accesses to both $x[j-1]$ and $x[j+1]$ will always be outside of the current thread's affinity.
With a greater block factor, these outside accesses can be reduced to only $2/B$ accesses on average.

Two parts of the code had to be changed: the array declarations (Figure~\ref{fig:laplace45a}) and the loop in \texttt{iteration()} and \texttt{copy\_array()} (Figure~\ref{fig:laplace45b}).

The effects of this change is dependent on $B$: similar to the results found in Table~\ref{tab:laplace3}, the code runs fastest when $B = 2^n$.
Whichever value is chosen, however, the program did not run faster than \texttt{ex4.upc} (Table~\ref{tab:laplace4}), but rather ran much slower (\href{https://github.com/adri326/pc40-upc/tree/main/laplace/ex5.upc}{the source code of this version can be found here}):

\begin{table}[ht]
  \centering\begin{tabular}{|c|c|c|}
    \hline
    Threads & Time (avg) & CI ($\sigma=0.01$) \\
    \hline
    2 & 959.2\us/iter & $\pm$ 3.9\us/iter \\
    4 & 863.9\us/iter & $\pm$ 16.1\us/iter \\
    8 & 691.6\us/iter & $\pm$ 6.1\us/iter \\
    16 & 581.5\us/iter & $\pm$ 4.1\us/iter \\
    32 & 536.9\us/iter & $\pm$ 4.0\us/iter \\
    \hline
  \end{tabular}
  \caption{Timing results for the third UPC implementation of the 1D Laplace solver, $B = 32$}
  \label{tab:laplace5}
\end{table}

When ran with $B = 1$, $THREADS = 32$, the code takes 318\us/iter $\pm$ 7.8\us/iter.
I do not know what causes this slowdown, but it seems like \texttt{upc\_forall} could contribute to it.

\begin{figure}[ht]
  \begin{subfigure}[b]{0.49\columnwidth}
    \begin{lstlisting}[style=C, numbers=none]
// ex4.upc:
shared double x_new[LEN];
shared double x[LEN];
shared double b[LEN];
    \end{lstlisting}
    \caption{Previous array declarations}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.49\columnwidth}
    \begin{lstlisting}[style=C, numbers=none]
// settings.h:
#define BLOCKSIZE 32

// ex5.upc:
shared[BLOCKSIZE] double x_new[LEN];
shared[BLOCKSIZE] double x[LEN];
shared[BLOCKSIZE] double b[LEN];
    \end{lstlisting}
    \caption{New array declarations with blocking factor}
  \end{subfigure}
  \caption{Modification of the array declarations to increase the blocking factor $B$.}
  \label{fig:laplace45a}
\end{figure}

\begin{figure}[ht]
  \begin{subfigure}[b]{0.49\columnwidth}
    \begin{lstlisting}[style=C, numbers=none]
// ex4.upc:
void iteration() {
    size_t i = MYTHREAD;
    if (MYTHREAD == 0) {
        i += THREADS;
        x_new[0] = x[0];
    }

    for (; i < LEN - 1; i += THREADS) {
        x_new[i] = 0.5 * (x[i-1] + x[i+1] + b[i]);
    }

    if (MYTHREAD == THREADS - 1) x_new[LEN - 1] = x[LEN - 1];

    upc_barrier;
}

void copy_array() {
    for (size_t i = MYTHREAD; i < LEN; i += THREADS) {
        x[i] = x_new[i];
    }
    upc_barrier;
}
    \end{lstlisting}
    \caption{Previous \texttt{iteration()} and \texttt{copy\_array()} implementations}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.49\columnwidth}
    \begin{lstlisting}[style=C, numbers=none]
// ex5.upc:
void iteration() {
    upc_forall (size_t i = 1; i < LEN - 1; i++; &x_new[i]) {
        x_new[i] = 0.5 * (x[i-1] + x[i+1] + b[i]);
    }

    if (MYTHREAD == 0) x_new[0] = x[0];
    if (MYTHREAD == THREADS - 1) x_new[LEN - 1] = x[LEN - 1];

    upc_barrier;
}

void copy_array() {
    upc_forall (size_t i = 0; i < LEN; i++; &x_new[i]) {
        x[i] = x_new[i];
    }
    upc_barrier;
}
    \end{lstlisting}
    \caption{New \texttt{iteration()} and \texttt{copy\_array()} implementations}
  \end{subfigure}
  \caption{Modification of the \texttt{iteration()} and \texttt{copy\_array()} functions to use \texttt{upc\_forall} to take into account the new blocking factor}
  \label{fig:laplace45b}
\end{figure}

\subsubsection{Note on the update/copy loop}

So far, the program has been running many iterations of the "main" loop, which calls \texttt{iteration()} and \texttt{copy\_array()}.
A \texttt{upc\_barrier;} call is necessary at the end of each of those two operations, as \texttt{copy\_array()} modifies $x$ and depends on the processed value of $x_{new}$, while \texttt{iteration()} modifies $x_{new}$ and depends on the copied value in $x$.

% \lstinputlisting[style=C]{2d_heat/heat_c.c}
\end{document}
